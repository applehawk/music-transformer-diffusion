{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KuxtZ-mfUZTJ"
      },
      "source": [
        "# Downloading Clips from the MusicCaps Dataset\n",
        "\n",
        "In this notebook, we see how you can use `yt-dlp` to download clips from the [MusicCaps](https://huggingface.co/datasets/google/MusicCaps) dataset from Google. The MusicCaps dataset contains music and their associated text captions. \n",
        "\n",
        "You could use a dataset like this to train a text-to-audio generation model ðŸ˜‰. \n",
        "\n",
        "Once we've downloaded the clips, we'll explore them using a [Gradio](https://gradio.app/) interface."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "68SO8YxOProJ"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "720.26s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n",
            "725.46s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
          ]
        }
      ],
      "source": [
        "%%capture\n",
        "! pip install datasets[audio] yt-dlp\n",
        "\n",
        "# For the interactive interface we'll need gradio\n",
        "! pip install gradio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "SeZLV1PCPyxW"
      },
      "outputs": [],
      "source": [
        "import subprocess\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "from datasets import load_dataset, Audio\n",
        "\n",
        "\n",
        "def download_clip(\n",
        "    video_identifier,\n",
        "    output_filename,\n",
        "    start_time,\n",
        "    end_time,\n",
        "    tmp_dir='/tmp/musiccaps',\n",
        "    num_attempts=5,\n",
        "    url_base='https://www.youtube.com/watch?v='\n",
        "):\n",
        "    status = False\n",
        "\n",
        "    command = f\"\"\"\n",
        "        yt-dlp --quiet --no-warnings -x --audio-format wav -f bestaudio -o \"{output_filename}\" --download-sections \"*{start_time}-{end_time}\" {url_base}{video_identifier}\n",
        "    \"\"\".strip()\n",
        "\n",
        "    attempts = 0\n",
        "    while True:\n",
        "        try:\n",
        "            output = subprocess.check_output(command, shell=True,\n",
        "                                                stderr=subprocess.STDOUT)\n",
        "        except subprocess.CalledProcessError as err:\n",
        "            attempts += 1\n",
        "            if attempts == num_attempts:\n",
        "                return status, err.output\n",
        "        else:\n",
        "            break\n",
        "\n",
        "    # Check if the video was successfully saved.\n",
        "    status = os.path.exists(output_filename)\n",
        "    return status, 'Downloaded'\n",
        "\n",
        "\n",
        "def main(\n",
        "    data_dir: str,\n",
        "    sampling_rate: int = 44100,\n",
        "    limit: int = None,\n",
        "    num_proc: int = 1,\n",
        "    writer_batch_size: int = 1000,\n",
        "):\n",
        "    \"\"\"\n",
        "    Download the clips within the MusicCaps dataset from YouTube.\n",
        "    Args:\n",
        "        data_dir: Directory to save the clips to.\n",
        "        sampling_rate: Sampling rate of the audio clips.\n",
        "        limit: Limit the number of examples to download.\n",
        "        num_proc: Number of processes to use for downloading.\n",
        "        writer_batch_size: Batch size for writing the dataset. This is per process.\n",
        "    \"\"\"\n",
        "\n",
        "    ds = load_dataset('google/MusicCaps', split='train')\n",
        "    if limit is not None:\n",
        "        print(f\"Limiting to {limit} examples\")\n",
        "        ds = ds.select(range(limit))\n",
        "\n",
        "    data_dir = Path(data_dir)\n",
        "    data_dir.mkdir(exist_ok=True, parents=True)\n",
        "\n",
        "    def process(example):\n",
        "        outfile_path = str(data_dir / f\"{example['ytid']}.wav\")\n",
        "        status = True\n",
        "        if not os.path.exists(outfile_path):\n",
        "            status = False\n",
        "            status, log = download_clip(\n",
        "                example['ytid'],\n",
        "                outfile_path,\n",
        "                example['start_s'],\n",
        "                example['end_s'],\n",
        "            )\n",
        "\n",
        "        example['audio'] = outfile_path\n",
        "        example['download_status'] = status\n",
        "        return example\n",
        "\n",
        "    return ds.map(\n",
        "        process,\n",
        "        num_proc=num_proc,\n",
        "        writer_batch_size=writer_batch_size,\n",
        "        keep_in_memory=False\n",
        "    ).cast_column('audio', Audio(sampling_rate=sampling_rate))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SfuUiBBwQkG4"
      },
      "source": [
        "## Load the Dataset\n",
        "\n",
        "Here we are limiting to the first 32 examples. Since Colab is constrained to 2 cores, downloading the whole dataset here would take hours.\n",
        "\n",
        "When running this on your own machine:\n",
        "  - you can set `limit=None` to download + process the full dataset. Feel free to do that here in Colab, it'll just take a long time.\n",
        "  - you should increase the `num_proc`, which will speed things up substantially\n",
        "  - If you run out of memory, try reducing the `writer_batch_size`, as by default, it will keep 1000 examples in memory *per worker*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "FV-nFNShP7Xd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Limiting to 128 examples\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Map (num_proc=2): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 128/128 [06:12<00:00,  2.91s/ examples]\n"
          ]
        }
      ],
      "source": [
        "ds = main('./music_data', num_proc=2, limit=128)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q4oDA-94RcOa"
      },
      "source": [
        "Let's explore the samples using a quick Gradio Interface ðŸ¤—"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "yYOHs59ISo-4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running on local URL:  http://127.0.0.1:7867\n",
            "\n",
            "To create a public link, set `share=True` in `launch()`.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"http://127.0.0.1:7867/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/Users/vladmac/Code/dl/music-lm-train/.env/lib/python3.12/site-packages/gradio/queueing.py\", line 521, in process_events\n",
            "    response = await route_utils.call_process_api(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/vladmac/Code/dl/music-lm-train/.env/lib/python3.12/site-packages/gradio/route_utils.py\", line 276, in call_process_api\n",
            "    output = await app.get_blocks().process_api(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/vladmac/Code/dl/music-lm-train/.env/lib/python3.12/site-packages/gradio/blocks.py\", line 1945, in process_api\n",
            "    result = await self.call_function(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/vladmac/Code/dl/music-lm-train/.env/lib/python3.12/site-packages/gradio/blocks.py\", line 1513, in call_function\n",
            "    prediction = await anyio.to_thread.run_sync(\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/vladmac/Code/dl/music-lm-train/.env/lib/python3.12/site-packages/anyio/to_thread.py\", line 56, in run_sync\n",
            "    return await get_async_backend().run_sync_in_worker_thread(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/vladmac/Code/dl/music-lm-train/.env/lib/python3.12/site-packages/anyio/_backends/_asyncio.py\", line 2177, in run_sync_in_worker_thread\n",
            "    return await future\n",
            "           ^^^^^^^^^^^^\n",
            "  File \"/Users/vladmac/Code/dl/music-lm-train/.env/lib/python3.12/site-packages/anyio/_backends/_asyncio.py\", line 859, in run\n",
            "    result = context.run(func, *args)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/vladmac/Code/dl/music-lm-train/.env/lib/python3.12/site-packages/gradio/utils.py\", line 831, in wrapper\n",
            "    response = f(*args, **kwargs)\n",
            "               ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/var/folders/s5/f_k8f4gn19l2f8nb2fvwb2sh0000gn/T/ipykernel_18288/2280949932.py\", line 4, in get_example\n",
            "    ex = ds[idx]\n",
            "         ~~^^^^^\n",
            "  File \"/Users/vladmac/Code/dl/music-lm-train/.env/lib/python3.12/site-packages/datasets/arrow_dataset.py\", line 2861, in __getitem__\n",
            "    return self._getitem(key)\n",
            "           ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/vladmac/Code/dl/music-lm-train/.env/lib/python3.12/site-packages/datasets/arrow_dataset.py\", line 2846, in _getitem\n",
            "    formatted_output = format_table(\n",
            "                       ^^^^^^^^^^^^^\n",
            "  File \"/Users/vladmac/Code/dl/music-lm-train/.env/lib/python3.12/site-packages/datasets/formatting/formatting.py\", line 633, in format_table\n",
            "    return formatter(pa_table, query_type=query_type)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/vladmac/Code/dl/music-lm-train/.env/lib/python3.12/site-packages/datasets/formatting/formatting.py\", line 397, in __call__\n",
            "    return self.format_row(pa_table)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/vladmac/Code/dl/music-lm-train/.env/lib/python3.12/site-packages/datasets/formatting/formatting.py\", line 438, in format_row\n",
            "    row = self.python_features_decoder.decode_row(row)\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/vladmac/Code/dl/music-lm-train/.env/lib/python3.12/site-packages/datasets/formatting/formatting.py\", line 216, in decode_row\n",
            "    return self.features.decode_example(row) if self.features else row\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/vladmac/Code/dl/music-lm-train/.env/lib/python3.12/site-packages/datasets/features/features.py\", line 1976, in decode_example\n",
            "    column_name: decode_nested_example(feature, value, token_per_repo_id=token_per_repo_id)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/vladmac/Code/dl/music-lm-train/.env/lib/python3.12/site-packages/datasets/features/features.py\", line 1341, in decode_nested_example\n",
            "    return schema.decode_example(obj, token_per_repo_id=token_per_repo_id)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/vladmac/Code/dl/music-lm-train/.env/lib/python3.12/site-packages/datasets/features/audio.py\", line 183, in decode_example\n",
            "    with xopen(path, \"rb\", download_config=download_config) as f:\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/vladmac/Code/dl/music-lm-train/.env/lib/python3.12/site-packages/datasets/utils/file_utils.py\", line 1219, in xopen\n",
            "    return open(main_hop, mode, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "FileNotFoundError: [Errno 2] No such file or directory: 'music_data/-tpq_bzSKes.wav'\n"
          ]
        }
      ],
      "source": [
        "import gradio as gr\n",
        "\n",
        "def get_example(idx):\n",
        "    ex = ds[idx]\n",
        "    return ex['audio']['path'], ex['caption']\n",
        "\n",
        "gr.Interface(\n",
        "    get_example,\n",
        "    inputs=gr.Slider(0, len(ds) - 1, value=0, step=1),\n",
        "    outputs=['audio', 'textarea'],\n",
        "    live=True\n",
        ").launch()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyPt2vYclAviWACVGOGOvupq",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
